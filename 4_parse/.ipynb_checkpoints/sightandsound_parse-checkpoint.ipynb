{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wikibase_url = '164.90.222.155'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13169877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "from wikibase_api import Wikibase\n",
    "import pathlib, rdflib, os, subprocess\n",
    "import pandas, pydash, datetime, requests\n",
    "import json, uuid\n",
    "\n",
    "in_path = pathlib.Path.cwd().resolve().parents[0] / '3_rdf' / 'sightandsound_rdf.rdf'\n",
    "out_path = pathlib.Path.cwd().resolve().parents[0] / '3_rdf' / 'sightandsound_rdf_utf8.rdf' \n",
    "\n",
    "with open(out_path, 'w') as data_write:\n",
    "    with open(in_path) as data:\n",
    "        data_read = data.read().encode('cp1252', errors='ignore').decode('utf8', errors='ignore')\n",
    "    data_write.write(data_read)\n",
    "\n",
    "print(len(data_read))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load up n-triples and break into phrases\n",
    "\n",
    "path = pathlib.Path.cwd().resolve().parents[0] / '3_rdf' / 'sightandsound_rdf_utf8.rdf'\n",
    "g = rdflib.Graph().parse(str(path), format=\"nt\")\n",
    "print(len(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# notebook_path = pathlib.Path.cwd()\n",
    "# print(notebook_path)\n",
    "# wikibase_path = pathlib.Path.home() / 'wikibase-docker'\n",
    "# if pathlib.Path.exists(wikibase_path) == False:\n",
    "#     os.chdir(pathlib.Path.home())\n",
    "#     subprocess.call(['git', 'clone', 'https://github.com/wmde/wikibase-docker.git'])\n",
    "#     os.chdir(notebook_path)\n",
    "#     print(pathlib.Path.cwd())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # fire up the instance\n",
    "# os.chdir(wikibase_path)\n",
    "# print(pathlib.Path.cwd())\n",
    "# subprocess.call(['docker-compose', 'up', '-d'])\n",
    "# os.chdir(notebook_path)\n",
    "# print(pathlib.Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createaccount': {'status': 'PASS', 'username': 'JupiterJones'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "S = requests.Session()\n",
    "wikiurl = f\"http://{wikibase_url}:8181\"\n",
    "endpoint = wikiurl + \"/w/api.php\"\n",
    "PARAMS_0 = {'action':\"query\",'meta':\"tokens\",'type':\"createaccount\",'format':\"json\"}\n",
    "R = S.get(url=endpoint, params=PARAMS_0)\n",
    "DATA = R.json()\n",
    "TOKEN = DATA['query']['tokens']['createaccounttoken']\n",
    "PARAMS_1 = {'action': \"createaccount\",'createtoken': TOKEN,'username': 'JupiterJones',\n",
    "    'password': 'ghosttoghost','retype': 'ghosttoghost','createreturnurl': wikiurl,'format': \"json\"}\n",
    "\n",
    "R = S.post(endpoint, data=PARAMS_1)\n",
    "DATA = R.json()\n",
    "\n",
    "print(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/paulduchesne/Git/sight-and-sound/4_parse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# bot config\n",
    "\n",
    "print(pathlib.Path.cwd())\n",
    "config = {\"apiUrl\":f\"http://{wikibase_url}:8181/w/api.php\",\n",
    "          \"loginCredentials\": {\"botUsername\":\"JupiterJones\", \"botPassword\":\"ghosttoghost\"},\n",
    "          \"summary\":\"data added via wikibase-api\"}\n",
    "configpath = pathlib.Path.cwd() / 'config.json' \n",
    "with open(configpath, 'w') as config_doc:\n",
    "    json.dump(config, config_doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rdflib.term.URIRef('urn:absolute:testontology#Film'): 'Q1', rdflib.term.URIRef('urn:absolute:testontology#Person'): 'Q2', rdflib.term.URIRef('urn:absolute:testontology#Country'): 'Q3', rdflib.term.URIRef('urn:absolute:testontology#Gender'): 'Q4', rdflib.term.URIRef('urn:absolute:testontology#Profession'): 'Q5'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ontology entities\n",
    "\n",
    "test_df = pandas.DataFrame(g, columns=['s','p','o'])\n",
    "\n",
    "def test(row):\n",
    "    if type(row['o']) == type(rdflib.term.Literal('h')):\n",
    "        return('literal')\n",
    "    else:\n",
    "        return('item')\n",
    "test_df['test'] = test_df.apply(test, axis=1)\n",
    "\n",
    "rdf_type = rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')\n",
    "ontology = list(test_df.loc[test_df.p.isin([rdf_type])]['o'].unique())\n",
    "\n",
    "wb = Wikibase(config_path=configpath)\n",
    "ont_dict = dict()\n",
    "\n",
    "for o in ontology:    \n",
    "    content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": str(o).split('#')[1]}}}\n",
    "    r = wb.entity.add('item', content=content)\n",
    "    identif = (pydash.get(r, 'entity.id'))\n",
    "    wb.description.set(identif, uuid.uuid4(), \"en\")  \n",
    "    ont_dict[o] = identif\n",
    "    \n",
    "print(ont_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 4895 of 4895; eta 2020-07-27 13:08:24.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# entities and labels\n",
    "\n",
    "wb = Wikibase(config_path=configpath)\n",
    "\n",
    "lab = rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label')\n",
    "entity = test_df.loc[test_df.p.isin([lab])]\n",
    "\n",
    "ent_data = list(zip(list(entity.s), list(entity.o)))\n",
    "ent_dict = dict()\n",
    "\n",
    "commencer = datetime.datetime.now()\n",
    "for n, x in enumerate(ent_data):\n",
    "    a, b = x[0], x[1]\n",
    "    \n",
    "    time_to_finish = ((((datetime.datetime.now()-commencer)/(n+1))*(len(ent_data)))+commencer).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'processing: {n+1} of {len(ent_data)}; eta {time_to_finish}.')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": b}}}\n",
    "    r = wb.entity.add('item', content=content)\n",
    "    identif = (pydash.get(r, 'entity.id'))\n",
    "    wb.description.set(identif, uuid.uuid4(), \"en\")  \n",
    "    ent_dict[a] = identif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'): 'P1', rdflib.term.URIRef('urn:absolute:testontology#of_country'): 'P2', rdflib.term.URIRef('urn:absolute:testontology#voted_by'): 'P3', rdflib.term.URIRef('urn:absolute:testontology#has_profession'): 'P4', rdflib.term.URIRef('urn:absolute:testontology#directed_by'): 'P5', rdflib.term.URIRef('urn:absolute:testontology#has_gender'): 'P6', rdflib.term.URIRef('urn:absolute:testontology#of_year'): 'P7'}\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# properties\n",
    "\n",
    "exempt = [rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label')]\n",
    "wb = Wikibase(config_path=configpath)\n",
    "prop = [x for x in pydash.uniq(list(zip(list(test_df.p), list(test_df.test)))) if x[0] not in exempt]\n",
    "\n",
    "prop_dict = dict()\n",
    "\n",
    "commencer = datetime.datetime.now()\n",
    "for n, x in enumerate(prop):\n",
    "    a, b = x[0], x[1]\n",
    "    if b == 'item':\n",
    "        content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": str(a).split('#')[1]}}, 'datatype':'wikibase-item'}\n",
    "    else:\n",
    "        content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": str(a).split('#')[1]}}, 'datatype':'string'}\n",
    "    r = wb.entity.add('property', content=content)\n",
    "    identif = (pydash.get(r, 'entity.id'))\n",
    "    wb.description.set(identif, uuid.uuid4(), \"en\")  \n",
    "    prop_dict[a] = identif\n",
    "    \n",
    "print(prop_dict)\n",
    "print(len(prop_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2672</td>\n",
       "      <td>P1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3851</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q2829</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3657</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q1891</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q896</td>\n",
       "      <td>P3</td>\n",
       "      <td>Q2503</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4411</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q4270</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q806</td>\n",
       "      <td>P3</td>\n",
       "      <td>Q302</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q3799</td>\n",
       "      <td>P3</td>\n",
       "      <td>Q4406</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q1136</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q853</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q68</td>\n",
       "      <td>P3</td>\n",
       "      <td>Q2540</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q1679</td>\n",
       "      <td>P4</td>\n",
       "      <td>Q4681</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q3052</td>\n",
       "      <td>P5</td>\n",
       "      <td>Q4454</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q932</td>\n",
       "      <td>P5</td>\n",
       "      <td>Q1329</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q1310</td>\n",
       "      <td>P5</td>\n",
       "      <td>Q378</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q3229</td>\n",
       "      <td>P1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q1824</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q1342</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q4279</td>\n",
       "      <td>P6</td>\n",
       "      <td>Q1456</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q2468</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q853</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q4751</td>\n",
       "      <td>P7</td>\n",
       "      <td>1980</td>\n",
       "      <td>literal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q1890</td>\n",
       "      <td>P1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q857</td>\n",
       "      <td>P1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        s   p      o     test\n",
       "0   Q2672  P1     Q1     item\n",
       "1   Q3851  P2  Q2829     item\n",
       "2   Q3657  P2  Q1891     item\n",
       "3    Q896  P3  Q2503     item\n",
       "4   Q4411  P2  Q4270     item\n",
       "5    Q806  P3   Q302     item\n",
       "6   Q3799  P3  Q4406     item\n",
       "7   Q1136  P2   Q853     item\n",
       "8     Q68  P3  Q2540     item\n",
       "9   Q1679  P4  Q4681     item\n",
       "10  Q3052  P5  Q4454     item\n",
       "11   Q932  P5  Q1329     item\n",
       "12  Q1310  P5   Q378     item\n",
       "13  Q3229  P1     Q2     item\n",
       "14  Q1824  P2  Q1342     item\n",
       "15  Q4279  P6  Q1456     item\n",
       "16  Q2468  P2   Q853     item\n",
       "17  Q4751  P7   1980  literal\n",
       "18  Q1890  P1     Q2     item\n",
       "19   Q857  P1     Q2     item"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# replace rdf values with wikibase codes\n",
    "\n",
    "altered_state = test_df.copy()\n",
    "\n",
    "for a,b in ent_dict.items():\n",
    "    altered_state.loc[altered_state.s.isin([a]), 's'] = b\n",
    "for a,b in prop_dict.items():\n",
    "    altered_state.loc[altered_state.p.isin([a]), 'p'] = b\n",
    "for a,b in ont_dict.items():\n",
    "    altered_state.loc[altered_state.o.isin([a]), 'o'] = b\n",
    "for a,b in ent_dict.items():\n",
    "    altered_state.loc[altered_state.o.isin([a]), 'o'] = b    \n",
    "\n",
    "altered_state.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 30602 of 30602; eta 2020-07-27 22:18:22.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# claims\n",
    "\n",
    "wb = Wikibase(config_path=configpath)\n",
    "exempt = [rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label')]\n",
    "\n",
    "claims = altered_state.copy()\n",
    "claims = claims.loc[~claims.p.isin(exempt)]\n",
    "\n",
    "claim_data = list(zip(list(claims.s),list(claims.p),list(claims.o),list(claims.test)))\n",
    "commencer = datetime.datetime.now()\n",
    "for n, x in enumerate(claim_data):\n",
    "    a, b, c, d = x[0], x[1], x[2], x[3]\n",
    "\n",
    "    time_to_finish = ((((datetime.datetime.now()-commencer)/(n+1))*(len(claim_data)))+commencer).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'processing: {n+1} of {len(claim_data)}; eta {time_to_finish}.')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if d == 'literal':\n",
    "        wb.claim.add(a, b, c)\n",
    "    else:\n",
    "        wb.claim.add(a, b, {'entity-type':'item', 'id':c})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
