{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-30 22:54:03.148638\n",
      "17604729\n",
      "40492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "from wikibase_api import Wikibase\n",
    "import pathlib, rdflib, os, subprocess\n",
    "import pandas, pydash, datetime, requests\n",
    "import json, uuid\n",
    "\n",
    "wikibase_url = '138.197.181.117'\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "in_path = pathlib.Path.cwd().resolve().parents[0] / '4-rdf' / 'sightandsound-rdf.rdf'\n",
    "out_path = pathlib.Path.cwd().resolve().parents[0] / '5-inject' / 'sightandsound-rdf-utf8.rdf' \n",
    "\n",
    "with open(out_path, 'w') as data_write:\n",
    "    with open(in_path) as data:\n",
    "        data_read = data.read().encode('cp1252', errors='ignore').decode('utf8', errors='ignore')\n",
    "    data_write.write(data_read)\n",
    "\n",
    "print(len(data_read))\n",
    "path = pathlib.Path.cwd().resolve().parents[0] / '5-inject' / 'sightandsound-rdf-utf8.rdf' \n",
    "g = rdflib.Graph().parse(str(path), format=\"nt\")\n",
    "print(len(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createaccount': {'status': 'PASS', 'username': 'JupiterJones'}}\n",
      "2020-09-30 22:54:14.787765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate a bot\n",
    "# shamelessly taken from here https://www.mediawiki.org/wiki/API:Account_creation\n",
    "\n",
    "S = requests.Session()\n",
    "wikiurl = f\"http://{wikibase_url}:8181\"\n",
    "endpoint = wikiurl + \"/w/api.php\"\n",
    "PARAMS_0 = {'action':\"query\",'meta':\"tokens\",'type':\"createaccount\",'format':\"json\"}\n",
    "R = S.get(url=endpoint, params=PARAMS_0)\n",
    "DATA = R.json()\n",
    "TOKEN = DATA['query']['tokens']['createaccounttoken']\n",
    "PARAMS_1 = {'action': \"createaccount\",'createtoken': TOKEN,'username': 'JupiterJones',\n",
    "    'password': 'ghosttoghost','retype': 'ghosttoghost','createreturnurl': wikiurl,'format': \"json\"}\n",
    "\n",
    "R = S.post(endpoint, data=PARAMS_1)\n",
    "DATA = R.json()\n",
    "\n",
    "print(DATA)\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-30 22:54:14.805203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load config\n",
    "\n",
    "config = {\"apiUrl\":f\"http://{wikibase_url}:8181/w/api.php\",\n",
    "          \"loginCredentials\": {\"botUsername\":\"JupiterJones\", \"botPassword\":\"ghosttoghost\"},\n",
    "          \"summary\":\"data added via wikibase-api\"}\n",
    "configpath = pathlib.Path.cwd() / 'config.json' \n",
    "with open(configpath, 'w') as config_doc:\n",
    "    json.dump(config, config_doc)\n",
    "print(datetime.datetime.now())    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-30 22:54:25.354224\n",
      "{rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#Film'): 'Q1', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#Person'): 'Q2', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#Country'): 'Q3', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#Profession'): 'Q4', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#Gender'): 'Q5'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# author ontology entities\n",
    "\n",
    "test_df = pandas.DataFrame(g, columns=['s','p','o'])\n",
    "\n",
    "def test(row):\n",
    "    if type(row['o']) == type(rdflib.term.Literal('h')):\n",
    "        return('literal')\n",
    "    else:\n",
    "        return('item')\n",
    "test_df['test'] = test_df.apply(test, axis=1)\n",
    "\n",
    "rdf_type = rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')\n",
    "ontology = list(test_df.loc[test_df.p.isin([rdf_type])]['o'].unique())\n",
    "\n",
    "wb = Wikibase(config_path=configpath)\n",
    "ont_dict = dict()\n",
    "\n",
    "for o in ontology:    \n",
    "    content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": str(o).split('#')[1]}}}\n",
    "    r = wb.entity.add('item', content=content)\n",
    "    identif = (pydash.get(r, 'entity.id'))\n",
    "    wb.description.set(identif, uuid.uuid4(), \"en\")  \n",
    "    ont_dict[o] = identif\n",
    "\n",
    "print(datetime.datetime.now())    \n",
    "print(ont_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 01:34:45.433958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# author entities and labels\n",
    "\n",
    "wb = Wikibase(config_path=configpath)\n",
    "\n",
    "lab = rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label')\n",
    "entity = test_df.loc[test_df.p.isin([lab])]\n",
    "\n",
    "ent_data = list(zip(list(entity.s), list(entity.o)))\n",
    "ent_dict = dict()\n",
    "\n",
    "commencer = datetime.datetime.now()\n",
    "for n, x in enumerate(ent_data):\n",
    "    a, b = x[0], x[1]\n",
    "    \n",
    "    time_to_finish = ((((datetime.datetime.now()-commencer)/(n+1))*(len(ent_data)))+commencer).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'processing: {n+1} of {len(ent_data)}; eta {time_to_finish}.')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": b}}}\n",
    "    r = wb.entity.add('item', content=content)\n",
    "    identif = (pydash.get(r, 'entity.id'))\n",
    "    wb.description.set(identif, uuid.uuid4(), \"en\")  \n",
    "    ent_dict[a] = identif\n",
    "\n",
    "print(datetime.datetime.now())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 01:35:00.964483\n",
      "{rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#of_year'): 'P1', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#directed_by'): 'P2', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#has_profession'): 'P3', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#imdb_identifier'): 'P4', rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'): 'P5', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#voted_by'): 'P6', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#wikidata_identifier'): 'P7', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#has_gender'): 'P8', rdflib.term.URIRef('urn:absolute:sight-and-sound-ontology#of_country'): 'P9'}\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# author properties\n",
    "\n",
    "exempt = [rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label')]\n",
    "wb = Wikibase(config_path=configpath)\n",
    "prop = [x for x in pydash.uniq(list(zip(list(test_df.p), list(test_df.test)))) if x[0] not in exempt]\n",
    "\n",
    "prop_dict = dict()\n",
    "\n",
    "commencer = datetime.datetime.now()\n",
    "for n, x in enumerate(prop):\n",
    "    a, b = x[0], x[1]\n",
    "    if b == 'item':\n",
    "        content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": str(a).split('#')[1]}}, 'datatype':'wikibase-item'}\n",
    "    else:\n",
    "        content = {\"labels\": {\"en\": {\"language\": \"en\", \"value\": str(a).split('#')[1]}}, 'datatype':'string'}\n",
    "    r = wb.entity.add('property', content=content)\n",
    "    identif = (pydash.get(r, 'entity.id'))\n",
    "    wb.description.set(identif, uuid.uuid4(), \"en\")  \n",
    "    prop_dict[a] = identif\n",
    "\n",
    "print(datetime.datetime.now())    \n",
    "print(prop_dict)\n",
    "print(len(prop_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 01:36:34.391909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q6</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#label</td>\n",
       "      <td>The Long Goodbye</td>\n",
       "      <td>literal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4255</td>\n",
       "      <td>P1</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>literal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2712</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q672</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2076</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q3509</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3502</td>\n",
       "      <td>P3</td>\n",
       "      <td>Q4587</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       s                                           p                 o  \\\n",
       "0     Q6  http://www.w3.org/2000/01/rdf-schema#label  The Long Goodbye   \n",
       "1  Q4255                                          P1            1980.0   \n",
       "2  Q2712                                          P2              Q672   \n",
       "3  Q2076                                          P2             Q3509   \n",
       "4  Q3502                                          P3             Q4587   \n",
       "\n",
       "      test  \n",
       "0  literal  \n",
       "1  literal  \n",
       "2     item  \n",
       "3     item  \n",
       "4     item  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# replace rdf values with fresh wikibase codes\n",
    "\n",
    "altered_state = test_df.copy()\n",
    "\n",
    "for a,b in ent_dict.items():\n",
    "    altered_state.loc[altered_state.s.isin([a]), 's'] = b\n",
    "for a,b in prop_dict.items():\n",
    "    altered_state.loc[altered_state.p.isin([a]), 'p'] = b\n",
    "for a,b in ont_dict.items():\n",
    "    altered_state.loc[altered_state.o.isin([a]), 'o'] = b\n",
    "for a,b in ent_dict.items():\n",
    "    altered_state.loc[altered_state.o.isin([a]), 'o'] = b    \n",
    "\n",
    "print(datetime.datetime.now())\n",
    "altered_state.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 12:33:00.814112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# author claims\n",
    "\n",
    "wb = Wikibase(config_path=configpath)\n",
    "exempt = [rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label')]\n",
    "\n",
    "claims = altered_state.copy()\n",
    "claims = claims.loc[~claims.p.isin(exempt)]\n",
    "\n",
    "claim_data = list(zip(list(claims.s),list(claims.p),list(claims.o),list(claims.test)))\n",
    "commencer = datetime.datetime.now()\n",
    "for n, x in enumerate(claim_data):\n",
    "    a, b, c, d = x[0], x[1], x[2], x[3]\n",
    "\n",
    "    time_to_finish = ((((datetime.datetime.now()-commencer)/(n+1))*(len(claim_data)))+commencer).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'processing: {n+1} of {len(claim_data)}; eta {time_to_finish}.')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if d == 'literal':\n",
    "        wb.claim.add(a, b, c)\n",
    "    else:\n",
    "        wb.claim.add(a, b, {'entity-type':'item', 'id':c})\n",
    "\n",
    "print(datetime.datetime.now())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
